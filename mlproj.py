# -*- coding: utf-8 -*-
"""MLProj.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1juZszlCOa7gzumRYjwkEUhgY2jv3BUKv
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
# %matplotlib inline
import scipy.stats as stats

from google.colab import files
uploaded = files.upload()

df = pd.read_csv("diamonds.csv")

"""***EDA***"""

df.drop (df.columns [[0]], axis= 1 , inplace= True ) #удалили 1 ноунейм столбец

df.info()

print(df.shape)

df.sample(5)

df.isnull().sum().sum () #посмотрели кол-во пропусков в датасете - ноль

sns.boxplot(df['price'])

sns.boxplot(df['carat'])

sns.boxplot(df['table'])

sns.boxplot(df['depth'])

sns.boxplot(df['x'])

sns.boxplot(df['y'])

sns.boxplot(df['z'])

#Выявление и избавление от выбросов по Z-score

#find absolute value of z-score for each observation
z = np.abs(stats.zscore(df[['carat', 'price', 'depth', 'table', 'x', 'y', 'z']]))

#only keep rows in dataframe with all z-scores less than absolute value of 3
data_clean = df[(z<3).all(axis=1)]

#find how many rows are left in the dataframe
data_clean.shape

#Выявление и избавление от выбросов по IQR

#find Q1, Q3, and interquartile range for each column
Q1 = data_clean[['carat', 'price', 'depth', 'table', 'x', 'y', 'z']].quantile(q=.25)
Q3 = data_clean[['carat', 'price', 'depth', 'table', 'x', 'y', 'z']].quantile(q=.75)
IQR = Q3 - Q1

#only keep rows in dataframe that have values within 1.5\*IQR of Q1 and Q3
df_clean = data_clean[~((data_clean < (Q1-1.5*IQR)) | (data_clean > (Q3+1.5*IQR))).any(axis=1)]

#find how many rows are left in the dataframe
df_clean.shape

df_clean.describe()

###Unvariate Analysis###

cat_feat = ['cut', 'color', 'clarity']
feature = cat_feat[0]
count = df_clean[feature].value_counts()

#Categorical
percent = 100 * df_clean[feature].value_counts(normalize = True)
da = pd.DataFrame({'Sample' : count, 'Percent' : percent.round(1)})
print(da)
plt.figure()
sns.countplot(x = feature, data = df_clean, palette = 'gist_rainbow', order = df_clean['cut'].value_counts().index)

feature = cat_feat[1]
count = df_clean[feature].value_counts()
percent = 100 * df_clean[feature].value_counts(normalize = True)
dm = pd.DataFrame({'Sample' : count, 'Percent' : percent.round(1)})
print(dm)
sns.countplot(x = feature, data = df_clean, palette = 'gist_rainbow', order = df_clean['color'].value_counts().index)

feature = cat_feat[2]
count = df_clean[feature].value_counts()
percent = 100 * df_clean[feature].value_counts(normalize = True)
dc = pd.DataFrame({'Sample' : count, 'Percent' : percent.round(1)})
print(dc)
sns.countplot(x = feature, data = df_clean, palette = 'gist_rainbow', order = df_clean['clarity'].value_counts().index)

sns.set_style('darkgrid')
plt.title('Зависимость между весом бриллианта и его ценой', size=16)
plt.xlabel('Вес бриллианта', size=12)
plt.ylabel('Цена', size=12)
sns.scatterplot(x ='carat', y='price', data=df_clean, edgecolor='k', style='cut', palette='cubehelix', style_order=['Ideal','Premium', 'Good', 'Very Good', 'Fair'])
plt.show()

#На последующих диаграммах рассеивания не делали разделение на категориальные переменные, т.к. по графику сложно интерпритировать из-за большого кол-ва наблюдений.
sns.set_style('darkgrid')
plt.title('Зависимость между весом бриллианта и его длиной', size=16)
plt.xlabel('Вес бриллианта', size=12)
plt.ylabel('Длина', size=12)
sns.scatterplot(x ='carat', y='x', data=df_clean, edgecolor='k', palette='cubehelix')
plt.show()
#Зависимость с шириной и глубиной (y и z) прослеживается похожая, т.к. x, y, z - принадлежат к параметрам размерности и будут вести себя похожим образом.

sns.set_style('darkgrid')
plt.title('Зависимость между ценой бриллианта и его длиной', size=16)
plt.xlabel('Цена', size=12)
plt.ylabel('Длина', size=12)
sns.scatterplot(x ='price', y='x', data=df_clean, edgecolor='k', palette='cubehelix')
plt.show()
#Зависимость с шириной и глубиной (y и z) прослеживается похожая, т.к. x, y, z - принадлежат к параметрам размерности и будут вести себя похожим образом.

#Numeric
df_clean.hist(bins = 20, figsize = (15, 15), color = "crimson", grid = False)
plt.show()

###Multivariate Analysis###

#Categorical
categorical = df_clean.select_dtypes(include = 'object').columns.to_list()

for col in cat_feat :
  sns.catplot(x = col, y = 'price', kind = 'bar', dodge = False, height = 4, aspect = 3, data = df_clean, palette = 'gist_rainbow')
  plt.title("Mean price - {}".format(col))

for col in cat_feat :
  sns.catplot(x = col, y = 'carat', kind = 'bar', dodge = False, height = 4, aspect = 3, data = df_clean, palette = 'gist_rainbow')
  plt.title("Mean carat - {}".format(col))

for col in cat_feat :
  sns.catplot(x = col, y = 'x', kind = 'bar', dodge = False, height = 4, aspect = 3, data = df_clean, palette = 'gist_rainbow')
  plt.title("Mean length - {}".format(col))

#Numeric
sns.pairplot(df_clean, diag_kind = 'kde')

#Correlation Score
plt.figure(figsize = (10,8))
correlation_matrix = df_clean.corr().round(2)

sns.heatmap(data = correlation_matrix, annot = True, cmap = 'rocket_r')
plt.title("Корреляционная матрица числовых переменных", size = 14)

"""***Выделаем самые лучшие категории в cut, color и clarity***"""

df_clean_ci = df_clean.loc[df_clean['cut'] == "Ideal"]
df_clean_ci

df_clean_cp = df_clean.loc[df_clean['cut'] == "Premium"]
df_clean_cp

df_clean_cu = pd.concat([df_clean_ci, df_clean_cp])
df_clean_cu

df_clean_cut = pd.get_dummies(df_clean_cu, columns=['cut'], drop_first= True) #ВОТ ЭТО!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
df_clean_cut

df_clean_d = df_clean.loc[df_clean['color'] == "D"]
df_clean_d

df_clean_e = df_clean.loc[df_clean['color'] == "E"]
df_clean_e

df_clean_co = pd.concat([df_clean_d, df_clean_e])
df_clean_co

df_clean_col = pd.get_dummies(df_clean_co, columns=['color'], drop_first= True) #ВОТ ЭТО!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
df_clean_col

df_clean_cif = df_clean.loc[df_clean['clarity'] == "IF"]
df_clean_cif

df_clean_cvv = df_clean.loc[df_clean['clarity'] == "VVS1"]
df_clean_cvv

df_clean_cl = pd.concat([df_clean_cif, df_clean_cvv])
df_clean_cl

df_clean_cla = pd.get_dummies(df_clean_cl, columns=['clarity'], drop_first= True) #ВОТ ЭТО!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
df_clean_cla

"""***KNN***"""

from sklearn.model_selection import train_test_split

#Выделяем features - x и target - y
y = df_clean_cut["cut_Premium"].values
X = df_clean_cut[["price", "carat", "x", "y", "z"]].values

#Делим данные на обучающую и тестовую выборки
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)


from sklearn.preprocessing import StandardScaler

#Нормализуем данные
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

X.shape, y.shape

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=8)

knn.fit(X_train, y_train)

print(knn.score(X_test, y_test))

y_pred = knn.predict(X_test)

print(knn.predict_proba(X_test))

print('Predictions: {}'.format(y_pred))

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc

accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

#Моделируем k с помощью Cross Validation

k_values = [i for i in range (1,31)]
scores = []

scaler = StandardScaler()
X = scaler.fit_transform(X)

from sklearn.model_selection import cross_val_score

for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k)
    score = cross_val_score(knn, X, y, cv=5)
    scores.append(np.mean(score))

sns.lineplot(x = k_values, y = scores, marker = 'o')
plt.xlabel("K Values")
plt.ylabel("Accuracy Score")

best_index = np.argmax(scores)
best_k = k_values[best_index]

knn = KNeighborsClassifier(n_neighbors=best_k)
knn.fit(X_train, y_train)

y_pred_m = knn.predict(X_test)

from sklearn.metrics import precision_score

print("Precision Score : ",precision_score(y_test, y_pred, average=None, zero_division= 0))
print("Recall Score : ",recall_score(y_test, y_pred, average=None, zero_division= 0))

accuracy = accuracy_score(y_test, y_pred)

print("Accuracy Score:", accuracy)

print(knn.predict_proba(X_test))

print("Predictions: {}, Actual Values: {}".format(y_pred_m[:2], y_test[:2]))

from sklearn.model_selection import train_test_split

#Выделяем features - x и target - y
y1 = df_clean_col["color_E"].values
X1 = df_clean_col[["price", "carat", "x", "y", "z"]].values


#Делим данные на обучающую и тестовую выборки
X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42, stratify=y1)


from sklearn.preprocessing import StandardScaler

#Нормализуем данные
scaler1 = StandardScaler()
X_train1 = scaler1.fit_transform(X_train1)
X_test1 = scaler1.transform(X_test1)

X1.shape, y1.shape

from sklearn.neighbors import KNeighborsClassifier

knn1 = KNeighborsClassifier(n_neighbors=8)

knn1.fit(X_train1, y_train1)

print(knn1.score(X_test1, y_test1))

y_pred1 = knn1.predict(X_test1)

print(knn1.predict_proba(X_test1))

print('Predictions: {}'.format(y_pred1))

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc

accuracy1 = accuracy_score(y_test1, y_pred1)
print("Accuracy:", accuracy1)

#Моделируем k с помощью Cross Validation

k_values1 = [i for i in range (1,31)]
scores1 = []

scaler1 = StandardScaler()
X1 = scaler1.fit_transform(X1)

from sklearn.model_selection import cross_val_score

for k in k_values:
    knn1 = KNeighborsClassifier(n_neighbors=k)
    score1 = cross_val_score(knn1, X1, y1, cv=5)
    scores1.append(np.mean(score1))

sns.lineplot(x = k_values1, y = scores1, marker = 'o')
plt.xlabel("K Values")
plt.ylabel("Accuracy Score")

best_index1 = np.argmax(scores1)
best_k1 = k_values1[best_index1]

knn1 = KNeighborsClassifier(n_neighbors=best_k1)
knn1.fit(X_train1, y_train1)

y_pred_m1 = knn1.predict(X_test1)

from sklearn.metrics import precision_score

print("Precision Score : ",precision_score(y_test1, y_pred1, average=None, zero_division= 0))
print("Recall Score : ",recall_score(y_test1, y_pred1, average=None, zero_division= 0))

accuracy1 = accuracy_score(y_test1, y_pred1)

print("Accuracy Score:", accuracy1)

print(knn1.predict_proba(X_test1))

print("Predictions: {}, Actual Values: {}".format(y_pred_m1[:2], y_test1[:2]))

from sklearn.model_selection import train_test_split

#Выделяем features - x и target - y
y2 = df_clean_cla["clarity_VVS1"].values
X2 = df_clean_cla[["price", "carat", "x", "y", "z"]].values

#Делим данные на обучающую и тестовую выборки
X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42, stratify=y2)


from sklearn.preprocessing import StandardScaler

#Нормализуем данные
scaler2 = StandardScaler()
X_train2 = scaler2.fit_transform(X_train2)
X_test2 = scaler2.transform(X_test2)

from sklearn.neighbors import KNeighborsClassifier

knn2 = KNeighborsClassifier(n_neighbors=8)

knn2.fit(X_train2, y_train2)

print(knn2.score(X_test2, y_test2))

y_pred2 = knn2.predict(X_test2)

print(knn2.predict_proba(X_test2))

print('Predictions: {}'.format(y_pred2))

from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc

accuracy = accuracy_score(y_test2, y_pred2)
print("Accuracy:", accuracy)

#Моделируем k с помощью Cross Validation

k_values2 = [i for i in range (1,31)]
scores2 = []

scaler2 = StandardScaler()
X2 = scaler2.fit_transform(X2)

from sklearn.model_selection import cross_val_score

for k in k_values:
    knn2 = KNeighborsClassifier(n_neighbors=k)
    score2 = cross_val_score(knn2, X2, y2, cv=5)
    scores2.append(np.mean(score2))

sns.lineplot(x = k_values2, y = scores2, marker = 'o')
plt.xlabel("K Values")
plt.ylabel("Accuracy Score")

best_index2 = np.argmax(scores2)
best_k2 = k_values2[best_index2]

knn2 = KNeighborsClassifier(n_neighbors=best_k2)
knn2.fit(X_train2, y_train2)

y_pred_m2 = knn2.predict(X_test2)

from sklearn.metrics import precision_score

print("Precision Score : ",precision_score(y_test2, y_pred2, average=None, zero_division= 0))
print("Recall Score : ",recall_score(y_test2, y_pred2, average=None, zero_division= 0))

accuracy2 = accuracy_score(y_test2, y_pred2)

print("Accuracy Score:", accuracy2)

print(knn2.predict_proba(X_test2))

print("Predictions: {}, Actual Values: {}".format(y_pred_m2[:2], y_test2[:2]))

"""***Линейная регрессия***"""

dff = pd.get_dummies(df_clean, columns=['cut', 'color', 'clarity'], drop_first= True)

from sklearn.linear_model import LinearRegression


X_lin = dff.drop(["price", "table", "depth"], axis = 1).values
y_lin = dff["price"].values

from sklearn.model_selection import train_test_split

x_train_lin, x_test_lin, y_train_lin, y_test_lin = train_test_split(X_lin, y_lin,
        test_size = 0.3, random_state=42)


linreg = LinearRegression(fit_intercept = True)

linreg.fit(x_train_lin, y_train_lin)

print(linreg.intercept_ , linreg.coef_)

X_lin = dff.drop(["price", "table", "depth"], axis = 1)
pd.DataFrame(linreg.coef_, X_lin.columns, columns=["coef"]).sort_values( by="coef", ascending=False)

print(linreg.score(x_test_lin, y_test_lin)) #r_squared

lin_pred = linreg.predict(x_test_lin)
lin_pred

print("Predictions: {}, Actual Values: {}".format(lin_pred[:2], y_test_lin[:2]))

from sklearn.metrics import mean_squared_error

# Compute RMSE
rmse_lin = mean_squared_error(y_test_lin, lin_pred, squared=False)

print("RMSE: {}".format(rmse_lin))

"""***Random Forest***"""

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import recall_score

df_clean_cut_wit = df_clean_cut.drop(['table', 'depth', "color", "clarity"], axis=1)
df_clean_cut_wit

X_rf = df_clean_cut_wit.drop(["cut_Premium"], axis = 1).values
y_rf = df_clean_cut_wit["cut_Premium"].values

rf = RandomForestRegressor(n_estimators=100, max_depth = 5,
                           min_samples_leaf= 5, random_state=42)

X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X_rf, y_rf, test_size=0.25, random_state=16, stratify=y_rf)

from sklearn.preprocessing import StandardScaler
ss = StandardScaler()
X_train_scaled_rf = ss.fit_transform(X_train_rf)
X_test_scaled_rf = ss.transform(X_test_rf)
y_train_rf = np.array(y_train_rf)

rf.fit(X_train_scaled_rf, y_train_rf)

rf_pred = rf.predict(X_test_scaled_rf)

print(rf.score(X_test_scaled_rf, y_test_rf)) #r_squared

print("Predictions: {}, Actual Values: {}".format(rf_pred[:2], y_test_rf[:2]))

from sklearn.metrics import mean_squared_error

# Compute RMSE
rmse_rf = mean_squared_error(y_test_rf, rf_pred, squared=False)

print("RMSE: {}".format(rmse_rf))

feats = {}
for feature, importance in zip(df_clean_cut_wit.columns, rf.feature_importances_):
    feats[feature] = importance
importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-Importance'})
importances = importances.sort_values(by='Gini-Importance', ascending=False)
importances = importances.reset_index()
importances = importances.rename(columns={'index': 'Features'})
sns.set(font_scale = 5)
sns.set(style="whitegrid", color_codes=True, font_scale = 1.7)
fig, ax = plt.subplots()
fig.set_size_inches(30,15)
sns.barplot(x=importances['Gini-Importance'], y=importances['Features'], data=importances, color='skyblue')
plt.xlabel('Importance', fontsize=25, weight = 'bold')
plt.ylabel('Features', fontsize=25, weight = 'bold')
plt.title('Feature Importance', fontsize=25, weight = 'bold')
display(plt.show())
display(importances)

df_clean_col_wit = df_clean_col.drop(['table', 'depth', "cut", "clarity"], axis=1)
df_clean_col_wit

X_rfc = df_clean_col_wit.drop(["color_E"], axis = 1).values
y_rfc = df_clean_col_wit["color_E"].values

rfc = RandomForestRegressor(n_estimators=100, max_depth = 5,
                           min_samples_leaf= 5, random_state=42)

X_train_rfc, X_test_rfc, y_train_rfc, y_test_rfc = train_test_split(X_rfc, y_rfc, test_size=0.25, random_state=16, stratify=y_rfc)

from sklearn.preprocessing import StandardScaler
ssc = StandardScaler()
X_train_scaled_rfc = ssc.fit_transform(X_train_rfc)
X_test_scaled_rfc = ssc.transform(X_test_rfc)
y_train_rfc = np.array(y_train_rfc)

rfc.fit(X_train_scaled_rfc, y_train_rfc)

rfc_pred = rfc.predict(X_test_scaled_rfc)

print(rfc.score(X_test_scaled_rfc, y_test_rfc)) #r_squared

print("Predictions: {}, Actual Values: {}".format(rfc_pred[:2], y_test_rfc[:2]))

from sklearn.metrics import mean_squared_error

# Compute RMSE
rmse_rfc = mean_squared_error(y_test_rfc, rfc_pred, squared=False)

print("RMSE: {}".format(rmse_rfc))

feats = {}
for feature, importance in zip(df_clean_col_wit.columns, rfc.feature_importances_):
    feats[feature] = importance
importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-Importance'})
importances = importances.sort_values(by='Gini-Importance', ascending=False)
importances = importances.reset_index()
importances = importances.rename(columns={'index': 'Features'})
sns.set(font_scale = 5)
sns.set(style="whitegrid", color_codes=True, font_scale = 1.7)
fig, ax = plt.subplots()
fig.set_size_inches(30,15)
sns.barplot(x=importances['Gini-Importance'], y=importances['Features'], data=importances, color='skyblue')
plt.xlabel('Importance', fontsize=25, weight = 'bold')
plt.ylabel('Features', fontsize=25, weight = 'bold')
plt.title('Feature Importance', fontsize=25, weight = 'bold')
display(plt.show())
display(importances)

df_clean_cla_wit = df_clean_cla.drop(['table', 'depth', "cut", "color"], axis=1)
df_clean_cla_wit

X_rfcl = df_clean_cla_wit.drop(["clarity_VVS1"], axis = 1).values
y_rfcl = df_clean_cla_wit["clarity_VVS1"].values

rfcl = RandomForestRegressor(n_estimators=100, max_depth = 5,
                           min_samples_leaf= 5, random_state=42)

X_train_rfcl, X_test_rfcl, y_train_rfcl, y_test_rfcl = train_test_split(X_rfcl, y_rfcl, test_size=0.25, random_state=16, stratify=y_rfcl)

from sklearn.preprocessing import StandardScaler
sscl = StandardScaler()
X_train_scaled_rfcl = sscl.fit_transform(X_train_rfcl)
X_test_scaled_rfcl = sscl.transform(X_test_rfcl)
y_train_rfcl = np.array(y_train_rfcl)

rfcl.fit(X_train_scaled_rfcl, y_train_rfcl)

rfcl_pred = rfcl.predict(X_test_scaled_rfcl)

print(rfcl.score(X_test_scaled_rfcl, y_test_rfcl)) #r_squared

print("Predictions: {}, Actual Values: {}".format(rfcl_pred[:2], y_test_rfcl[:2]))

from sklearn.metrics import mean_squared_error

# Compute RMSE
rmse_rfcl = mean_squared_error(y_test_rfcl, rfcl_pred, squared=False)

print("RMSE: {}".format(rmse_rfcl))

feats = {}
for feature, importance in zip(df_clean_cla_wit.columns, rfcl.feature_importances_):
    feats[feature] = importance
importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'Gini-Importance'})
importances = importances.sort_values(by='Gini-Importance', ascending=False)
importances = importances.reset_index()
importances = importances.rename(columns={'index': 'Features'})
sns.set(font_scale = 5)
sns.set(style="whitegrid", color_codes=True, font_scale = 1.7)
fig, ax = plt.subplots()
fig.set_size_inches(30,15)
sns.barplot(x=importances['Gini-Importance'], y=importances['Features'], data=importances, color='skyblue')
plt.xlabel('Importance', fontsize=25, weight = 'bold')
plt.ylabel('Features', fontsize=25, weight = 'bold')
plt.title('Feature Importance', fontsize=25, weight = 'bold')
display(plt.show())
display(importances)

"""***Логистическая регрессия***"""

from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import Perceptron

X_log = df_clean_cut.drop(["cut_Premium", "color", "clarity", "table", "depth"], axis = 1).values
y_log = df_clean_cut["cut_Premium"].values

# instantiate the model (using the default parameters)
logreg = LogisticRegression(random_state=16, solver = 'liblinear', max_iter = 100)

X_train_log, X_test_log, y_train_log, y_test_log = train_test_split(X_log, y_log, test_size=0.25, random_state=16)

from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler

scaler_log = preprocessing.StandardScaler().fit(X_train_log)
scaler_log
StandardScaler()
X_scaled_log = scaler_log.transform(X_train_log)

# fit the model with data
logreg.fit(X_train_log, y_train_log)

log_pred = logreg.predict(X_test_log)

print("Predictions: {}, Actual Values: {}".format(log_pred[:2], y_test_log[:2]))

print(logreg.score(X_test_log, y_test_log)) #r_squared

rmse_log = mean_squared_error(y_test_log, log_pred, squared=False)

print("RMSE: {}".format(rmse_log))

from sklearn import metrics

cnf_matrix = metrics.confusion_matrix (y_test_log, log_pred)
cnf_matrix
#Истинно положительныe предсказанные значения = 4534; Истинно отрицательные предсказанные значения = 876; Ложноположительные предсказанные значения = 2117; Ложноотрицательные предсказанные значения = 464

log_pred_proba = logreg. predict_proba (X_test_log)[::,1]
fpr, tpr, _ = metrics. roc_curve (y_test_log, log_pred_proba)
auc = metrics. roc_auc_score (y_test_log, log_pred_proba)

plt.plot (fpr,tpr,label=" AUC= "+str(auc))
plt.legend(loc=4)
plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import Perceptron

X_logc = df_clean_col.drop(["color_E", "cut", "clarity", "table", "depth"], axis = 1).values
y_logc = df_clean_col["color_E"].values

# instantiate the model (using the default parameters)
logregc = LogisticRegression(random_state=16, solver = 'liblinear', max_iter = 100)

X_train_logc, X_test_logc, y_train_logc, y_test_logc = train_test_split(X_logc, y_logc, test_size=0.25, random_state=16)

from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler

scaler_logc = preprocessing.StandardScaler().fit(X_train_logc)
scaler_logc
StandardScaler()
X_scaled_logc = scaler_logc.transform(X_train_logc)

logregc.fit(X_train_logc, y_train_logc)

log_predc = logregc.predict(X_test_logc)

print("Predictions: {}, Actual Values: {}".format(log_predc[:2], y_test_logc[:2]))

print(logregc.score(X_test_logc, y_test_logc)) #r_squared

rmse_logc = mean_squared_error(y_test_logc, log_predc, squared=False)

print("RMSE: {}".format(rmse_logc))

from sklearn import metrics

cnf_matrixc = metrics.confusion_matrix (y_test_logc, log_predc)
cnf_matrixc
#Истинно положительныe предсказанные значения = 0; Истинно отрицательные предсказанные значения = 2181; Ложноположительные предсказанные значения = 0; Ложноотрицательные предсказанные значения = 1530

logc_pred_proba = logregc. predict_proba (X_test_logc)[::,1]
fprc, tprc, _ = metrics. roc_curve (y_test_logc, logc_pred_proba)
aucc = metrics. roc_auc_score (y_test_logc, logc_pred_proba)

plt.plot (fprc,tprc,label=" AUC= "+str(aucc))
plt.legend(loc=4)
plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import Perceptron

X_logcl = df_clean_cla.drop(["clarity_VVS1", "cut", "color", "table", "depth"], axis = 1).values
y_logcl = df_clean_cla["clarity_VVS1"].values

# instantiate the model (using the default parameters)
logregcl = LogisticRegression(random_state=16, solver = 'liblinear', max_iter = 100)

X_train_logcl, X_test_logcl, y_train_logcl, y_test_logcl = train_test_split(X_logcl, y_logcl, test_size=0.25, random_state=16)

from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler

scaler_logcl = preprocessing.StandardScaler().fit(X_train_logcl)
scaler_logcl
StandardScaler()
X_scaled_logcl = scaler_logcl.transform(X_train_logcl)

logregcl.fit(X_train_logcl, y_train_logcl)

log_predcl = logregcl.predict(X_test_logcl)

print("Predictions: {}, Actual Values: {}".format(log_predcl[:2], y_test_logcl[:2]))

print(logregcl.score(X_test_logcl, y_test_logcl)) #r_squared

rmse_logcl = mean_squared_error(y_test_logcl, log_predcl, squared=False)

print("RMSE: {}".format(rmse_logcl))

from sklearn import metrics

cnf_matrixcl = metrics.confusion_matrix (y_test_logcl, log_predcl)
cnf_matrixcl
#Истинно положительныe предсказанные значения = 0; Истинно отрицательные предсказанные значения = 856; Ложноположительные предсказанные значения = 0; Ложноотрицательные предсказанные значения = 404

logcl_pred_proba = logregcl. predict_proba (X_test_logcl)[::,1]
fprcl, tprcl, _ = metrics. roc_curve (y_test_logcl, logcl_pred_proba)
auccl = metrics. roc_auc_score (y_test_logcl, logcl_pred_proba)

plt.plot (fprcl,tprcl,label=" AUC= "+str(auccl))
plt.legend(loc=4)
plt.show()